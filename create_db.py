import os
import re
from call_embedding import get_embedding
from langchain_chroma import Chroma
from langchain_community.document_loaders import DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import (
    WebBaseLoader,      # ç½‘é¡µ
    PyPDFLoader,        # PDF
    UnstructuredWordDocumentLoader,  # Word æ–‡æ¡£
    TextLoader,         # æ–‡æœ¬æ–‡ä»¶
    DirectoryLoader,    # ç›®å½•
    CSVLoader,          # CSV
)

# åˆ›å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
def create_db(data_path, embeddings_model="BAAI/bge-large-zh-v1.5", chunk_size=1000):
    """ 
    è¯¥å‡½æ•°ç”¨äºåŠ è½½ PDF æ–‡ä»¶ï¼Œåˆ‡åˆ†æ–‡æ¡£ï¼Œç”Ÿæˆæ–‡æ¡£çš„åµŒå…¥å‘é‡ï¼Œåˆ›å»ºå‘é‡æ•°æ®åº“ã€‚
    å‚æ•°ï¼š
    - data_path: å¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„
    - embeddings_model: ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º "BAAI/bge-large-zh-v1.5"
    """

    persist_dir = "./chroma_db_all_docs"   # âœ… å¤šæ–‡æ¡£ç»Ÿä¸€å­˜å…¥åŒä¸€ä¸ªåº“

    # å¦‚æœå‘é‡åº“å­˜åœ¨ï¼Œç›´æ¥åŠ è½½
    if os.path.exists(persist_dir):
        print(f"ğŸ”„ å‘ç°å·²å­˜åœ¨å‘é‡åº“ï¼Œç›´æ¥åŠ è½½: {persist_dir}")
        embeddings = get_embedding(embeddings_model)
        return Chroma(persist_directory=persist_dir, embedding_function=embeddings)

    print("ğŸ“¥ é¦–æ¬¡è¿è¡Œï¼Œå¼€å§‹æ„å»ºå‘é‡åº“...")

    # 1. åŠ è½½æ•°æ®
    docs = []
    if os.path.isdir(data_path):
        loader = DirectoryLoader(
            data_path,
            glob="**/*.pdf",  # å¯ä»¥æ”¹ä¸º "*.pdf" æˆ– "*.txt" æˆ–ç»„åˆ
            loader_cls=PyPDFLoader
        )
        docs = loader.load()
    else:
        loader = PyPDFLoader(data_path)
        docs = loader.load()
    
    print(f"ğŸ“„ æ–‡æ¡£è½½å…¥å®Œæˆï¼Œå…± {len(docs)} æ¡è®°å½•")

    # 2. æ•°æ®æ¸…æ´—
    for doc in docs:
        # åŒ¹é…ä»»ä½•å­—ç¬¦ä¹‹é—´çš„æ¢è¡Œç¬¦ï¼ˆåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ç­‰ï¼‰
        pattern = re.compile(r'(.)\n(.)', re.DOTALL)
        doc.page_content = re.sub(pattern, r'\1\2', doc.page_content)
    print("æ–‡æœ¬æ¸…æ´—å®Œæˆ")

    # 3. æ–‡æœ¬åˆ‡åˆ†
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=int(chunk_size * 0.1),
        separators=["\n\n", "\n", " ", ""]  # ä¼˜å…ˆæŒ‰æ®µè½åˆ†å‰²
    )
    splits = text_splitter.split_documents(docs)

    # 4. å†™å…¥å‘é‡æ•°æ®åº“
    embeddings = get_embedding(embeddings_model)
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=persist_dir
    )

    print("âœ… å‘é‡åº“æ„å»ºå®Œæˆï¼å·²æŒä¹…åŒ–å­˜å‚¨ã€‚")
    return vectorstore
